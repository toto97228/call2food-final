// adapters/livekitAdapter.js
// Adapter LiveKit â†â†’ OpenAI Realtime
// âš ï¸ SQUELETTE : Ã  complÃ©ter quand on aura le SDK LiveKit branchÃ©.

const { createOpenAIRealtimeSession } = require('../openaiRealtimeCore');

async function initLiveKitAdapter(_server, { apiKey, model }) {
  console.log('ðŸš§ LiveKit adapter initialisÃ© (mode squelette, non connectÃ© Ã  LiveKit)');

  // On crÃ©e la session OpenAI, comme pour Twilio
  const session = await createOpenAIRealtimeSession({
    apiKey,
    model,
    onAudioDelta: (deltaBase64) => {
      // TODO : renvoyer lâ€™audio de rÃ©ponse vers LiveKit
      // Exemple logique (pseudo-code) :
      // livekitConnection.sendAudioFromBase64(deltaBase64);
    },
  });

  // === Fonctions Ã  brancher plus tard sur LiveKit ===

  // AppelÃ©e quand tu reÃ§ois de lâ€™audio du caller via LiveKit
  function handleIncomingLiveKitAudio(base64Ulaw) {
    // On pousse lâ€™audio vers OpenAI (mÃªme format g711 Î¼-law base64 que Twilio)
    session.appendAudio(base64Ulaw);
  }

  function cleanup() {
    try {
      if (session.ws && session.ws.readyState === 1) {
        session.ws.close();
      }
    } catch (e) {
      console.error('[LiveKit adapter] Error while closing OpenAI WS', e);
    }
  }

  // Pour lâ€™instant on retourne juste ces helpers,
  // quâ€™on branchera quand on aura le code LiveKit concret.
  return {
    handleIncomingLiveKitAudio,
    cleanup,
  };
}

module.exports = { initLiveKitAdapter };
